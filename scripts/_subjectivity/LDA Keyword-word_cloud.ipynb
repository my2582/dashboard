{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b36b2bdb3ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "%matplotlib inline\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', '-PRON-'])\n",
    "\n",
    "nlp = spacy.load('en', disable = ['parser'])\n",
    "punctuations = string.punctuation\n",
    "\n",
    "print('importing news')\n",
    "#df = pd.read_csv(r'/Users/msyeom/Google Drive/Machine Learning for Global Risk/Tr Corpus/Brexit.csv',header=0, encoding='utf-8').dropna(subset = ['body'])\n",
    "print('importing documents')\n",
    "\n",
    "# We drop a row only if both body and headline are NaN.\n",
    "df0 = pd.read_csv(r'./Raw data/BREXIT_RTRS_2015.csv', header=0,\n",
    "                  encoding='utf-8').dropna(subset=['body', 'headline'], how='all')\n",
    "df1 = pd.read_csv(r'./Raw data/BREXIT_RTRS_2016.csv', header=0,\n",
    "                  encoding='utf-8').dropna(subset=['body', 'headline'], how='all')\n",
    "df2 = pd.read_csv(r'./Raw data/BREXIT_RTRS_2017.csv', header=0,\n",
    "                  encoding='utf-8').dropna(subset=['body', 'headline'], how='all')\n",
    "df3 = pd.read_csv(r'./Raw data/BREXIT_RTRS_2018.csv', header=0,\n",
    "                  encoding='utf-8').dropna(subset=['body', 'headline'], how='all')\n",
    "df4 = pd.read_csv(r'./Raw data/BREXIT_RTRS_2019.csv', header=0,\n",
    "                  encoding='utf-8').dropna(subset=['body', 'headline'], how='all')\n",
    "\n",
    "df = df0.append([df1, df2, df3, df4], ignore_index=True, sort=True)\n",
    "\n",
    "# Fill na with \"\" to prevent errors during string-manipulation (cleaning)\n",
    "df['body'].fillna(\"\", inplace=True)\n",
    "df['headline'].fillna(\"\", inplace=True)\n",
    "\n",
    "# We drop if headline AND body are duplicated.\n",
    "df = df.drop_duplicates(['id']) \n",
    "df = df.drop_duplicates((['headline', 'body']))\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "#df.columns = ['Publication Number','Assignee - Standardized', 'Assignee - DWPI','Title','Abstract','Claims','Application Year','cecj']\n",
    "df.versionCreated = pd.to_datetime(df.versionCreated)\n",
    "\n",
    "df = df[~df.headline.str.startswith('MEDIA-')] # remove MEDIA articles\n",
    "\n",
    "def body_filt(txt):\n",
    "    txt = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", txt).replace(\"\\'\", \" \").replace('\\r', '').replace('\\n', '')\n",
    "    txt = re.sub(r\"http\\S+\", \"\",txt).strip()\n",
    "    txt = re.sub('<[^<]+?>', '', txt)\n",
    "    return txt\n",
    "\n",
    "df['body'] = df.body.apply(body_filt) # remove [] <> () + links \n",
    "\n",
    "#video link articles's description\n",
    "df.loc[df.body.str.startswith('Click the following link to watch video'), 'body'] = df[df.body.str.startswith('Click the following link to watch video')].body\\\n",
    "    .apply(lambda x : x.split('Description:')[1])\\\n",
    "    .apply(lambda x : x.split('Short Link:')[0])\\\n",
    "\n",
    "#remove other articles\n",
    "df.loc[df.headline.str.startswith('TAKE A LOOK-'), 'body'] = df[df.headline.str.startswith('TAKE A LOOK-')].body.apply(lambda x : x.split('Click on')[0])\n",
    "df['body'] = df['body'].apply(lambda x : \" \".join(x.split()))\n",
    "df\n",
    "\n",
    "keyword = ['article 50', 'backstop', 'canada model', 'canada-style', 'customs union', 'hard border', 'hard brexit', 'soft brexit','meaningful vote', 'no deal', 'no-deal', \n",
    "           'withdrawal agreement', 'wto', 'world trade organization', 'world trade organisation','single market', 'fta', 'free-trade agreement', 'divorce bill', 'free movement', 'norway', 'norwegian', 'norway style',\n",
    "           \"eea\", \"court of justice of the european union\", 'european court of justice', 'CJEU']\n",
    "\n",
    "print('tokenizing and filtering')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', '-PRON-'])\n",
    "stop_words.remove('no')\n",
    "def tokening(doc):\n",
    "    doc = re.sub(' +', ' ',doc)\n",
    "    doc = re.sub('[^A-Za-z0-9]+', ' ', doc)\n",
    "    doc = re.sub(r'\\d+', '', doc)\n",
    "    doc = word_tokenize(doc)\n",
    "    return [n for n in doc if not n in stop_words]\n",
    "\n",
    "tok = df.body.apply(tokening)\n",
    "join_tok = tok.apply(lambda x : \" \".join(x))\n",
    "del tok\n",
    "nlp_join_tok = join_tok.apply(nlp)\n",
    "del join_tok\n",
    "useless = ['DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL', 'GPE']\n",
    "\n",
    "def ent_filt(doc):\n",
    "    return [i.lemma_ for i in doc.ents if not i.label_ in useless]\n",
    "ent_list = nlp_join_tok.apply(ent_filt)\n",
    "\n",
    "def ent_filt(doc):\n",
    "    return [i.lemma_ for i in doc if i.lemma_ not in stop_words]\n",
    "print('entity processing')\n",
    "non_ent_list = nlp_join_tok.apply(ent_filt)\n",
    "del nlp_join_tok\n",
    "df_tf = pd.DataFrame()\n",
    "df_tf['named entity'] = ent_list\n",
    "df_tf['non-named entity'] = non_ent_list\n",
    "df_tf['pre ne']=df.body.apply(lambda x : [key for key in keyword if key in x.lower()])\n",
    "print('tf increasing')\n",
    "\n",
    "n=1\n",
    "m=5\n",
    "def chek(df_tf):\n",
    "    return np.append(np.tile(df_tf['named entity'],n), df_tf['non-named entity'])\n",
    "def chek2(df_tf):\n",
    "    if df_tf['pre ne'] != np.nan:\n",
    "        return np.append(np.tile(df_tf['pre ne'],m), df_tf['union'])\n",
    "    else:\n",
    "        returndf_tf['union']\n",
    "df_tf['union'] = df_tf.apply(chek, axis =1)\n",
    "df_tf['union2'] = df_tf.apply(chek2, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "id2word = corpora.dictionary.Dictionary(df_tf['union2'])\n",
    "corpus = df_tf['union2'].apply(lambda x : id2word.doc2bow(x))\n",
    "\n",
    "print('mallet importing')\n",
    "\n",
    "import os \n",
    "os.environ.update({'MALLET_HOME':r\"/Users/msyeom/Downloads/mallet-2.0.8\"})\n",
    "mallet_path = '/Users/msyeom/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "MALLET_HOME=r'/Users/msyeom/Downloads/mallet-2.0.8'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=8, id2word=id2word)\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "print('computing score')\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=df_tf['union2'], dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)\n",
    "\n",
    "\n",
    "import gensim    \n",
    "model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Save the corpus and dictionary for future use.\n",
    "\n",
    "Source: https://datascienceplus.com/topic-modeling-in-python-with-nltk-and-gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert to bag-of-words corpus\n",
    "#import pickle\n",
    "#pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in df_tf['union2']]\n",
    "corpora.MmCorpus.serialize('corpus.mm', doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary and corpus for future use.\n",
    "id2word.save('id2word.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model object that LDA algorithm, i.e., malletmodel2ldamodel() created.\n",
    "model.save('model.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-fd38a53b19e8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-fd38a53b19e8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    dictionary = corpora.Dictionary(text_data)corpus = [dictionary.doc2bow(text) for text in text_data]\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, \"vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>LONDON, Jan 2 - Britain wants to include finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>Jan 2 - Companies seeking to \"bulk up\" to offs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>* Cable vols off pre X-mas and long term lows,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>* 0.8919 = five-week high for EUR/GBP after st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3539</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>* U.S. FDA approves 46 novel drugs versus 22 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5806</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>Japan holiday today/Wed and next Monday dampen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>DUBLIN, Jan 2 - Ryanair recently applied for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>LONDON, Jan 2 - Yields on benchmark British gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2799</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>Jan 3 - Britain s FTSE 100 index is seen openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>Jan 3 - Britain s FTSE 100 index is seen openi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             6.0              0.2670   \n",
       "1            1             2.0              0.1640   \n",
       "2            2             7.0              0.5165   \n",
       "3            3             7.0              0.3312   \n",
       "4            4             5.0              0.3539   \n",
       "5            5             7.0              0.5806   \n",
       "6            6             5.0              0.2983   \n",
       "7            7             2.0              0.3152   \n",
       "8            8             5.0              0.2799   \n",
       "9            9             5.0              0.3341   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  eu, deal, union, brexit, agreement, british, b...   \n",
       "1  brexit, percent, year, economy, rate, month, b...   \n",
       "2  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "3  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "4  british, company, uk, group, business, britain...   \n",
       "5  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "6  british, company, uk, group, business, britain...   \n",
       "7  brexit, percent, year, economy, rate, month, b...   \n",
       "8  british, company, uk, group, business, britain...   \n",
       "9  british, company, uk, group, business, britain...   \n",
       "\n",
       "                                                Text  \n",
       "0  LONDON, Jan 2 - Britain wants to include finan...  \n",
       "1  Jan 2 - Companies seeking to \"bulk up\" to offs...  \n",
       "2  * Cable vols off pre X-mas and long term lows,...  \n",
       "3  * 0.8919 = five-week high for EUR/GBP after st...  \n",
       "4  * U.S. FDA approves 46 novel drugs versus 22 i...  \n",
       "5  Japan holiday today/Wed and next Monday dampen...  \n",
       "6  DUBLIN, Jan 2 - Ryanair recently applied for a...  \n",
       "7  LONDON, Jan 2 - Yields on benchmark British gi...  \n",
       "8  Jan 3 - Britain s FTSE 100 index is seen openi...  \n",
       "9  Jan 3 - Britain s FTSE 100 index is seen openi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=df.body.tolist()):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=df.body.tolist())\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>eu, european, brexit, london, britain, financi...</td>\n",
       "      <td>* French watchdog says EU must develop own cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>LONDON, Nov 16 - Some lawmakers in Prime Minis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>* Factory output falls 0.2 pct in Feb, first d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>* UK names suspects as Alexander Petrov and Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>european, percent, market, stock, share, europ...</td>\n",
       "      <td>* Euro zone shares hit ten year high * STOXX 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.7898   \n",
       "1        1.0              0.8000   \n",
       "2        2.0              0.7918   \n",
       "3        3.0              0.8579   \n",
       "4        4.0              0.9415   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  eu, european, brexit, london, britain, financi...   \n",
       "1  brexit, deal, party, vote, minister, eu, there...   \n",
       "2  brexit, percent, year, economy, rate, month, b...   \n",
       "3  trump, british, britain, trade, russian, presi...   \n",
       "4  european, percent, market, stock, share, europ...   \n",
       "\n",
       "                                                Text  \n",
       "0  * French watchdog says EU must develop own cap...  \n",
       "1  LONDON, Nov 16 - Some lawmakers in Prime Minis...  \n",
       "2  * Factory output falls 0.2 pct in Feb, first d...  \n",
       "3  * UK names suspects as Alexander Petrov and Ru...  \n",
       "4  * Euro zone shares hit ten year high * STOXX 6...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>0.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>0.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>958.0</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0.0442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>0.1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>0.1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>0.1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eu, european, brexit, london, britain, financi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>eu, european, brexit, london, britain, financi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12879</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12880</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12881</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12883</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brexit, deal, party, vote, minister, eu, there...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12885</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12886</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12887</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12888</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12889</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12890</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12891</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12893</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12894</th>\n",
       "      <td>4.0</td>\n",
       "      <td>european, percent, market, stock, share, europ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12895</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12897</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899</th>\n",
       "      <td>3.0</td>\n",
       "      <td>trump, british, britain, trade, russian, presi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12900</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>2.0</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>2.0</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>2.0</td>\n",
       "      <td>brexit, percent, year, economy, rate, month, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12906</th>\n",
       "      <td>5.0</td>\n",
       "      <td>british, company, uk, group, business, britain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12907</th>\n",
       "      <td>7.0</td>\n",
       "      <td>usd, gbp, high, low, risk, week, fed, eur, dol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12908</th>\n",
       "      <td>6.0</td>\n",
       "      <td>eu, deal, union, brexit, agreement, british, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dominant_Topic                                     Topic_Keywords  \\\n",
       "0                 6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "1                 2.0  brexit, percent, year, economy, rate, month, b...   \n",
       "2                 7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "3                 7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "4                 5.0  british, company, uk, group, business, britain...   \n",
       "5                 7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "6                 5.0  british, company, uk, group, business, britain...   \n",
       "7                 2.0  brexit, percent, year, economy, rate, month, b...   \n",
       "8                 5.0  british, company, uk, group, business, britain...   \n",
       "9                 5.0  british, company, uk, group, business, britain...   \n",
       "10                3.0  trump, british, britain, trade, russian, presi...   \n",
       "11                7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12                3.0  trump, british, britain, trade, russian, presi...   \n",
       "13                3.0  trump, british, britain, trade, russian, presi...   \n",
       "14                3.0  trump, british, britain, trade, russian, presi...   \n",
       "15                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "16                3.0  trump, british, britain, trade, russian, presi...   \n",
       "17                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "18                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "19                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "20                5.0  british, company, uk, group, business, britain...   \n",
       "21                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "22                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "23                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "24                0.0  eu, european, brexit, london, britain, financi...   \n",
       "25                0.0  eu, european, brexit, london, britain, financi...   \n",
       "26                7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "27                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "28                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "29                1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "...               ...                                                ...   \n",
       "12879             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12880             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12881             5.0  british, company, uk, group, business, britain...   \n",
       "12882             1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "12883             6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "12884             1.0  brexit, deal, party, vote, minister, eu, there...   \n",
       "12885             3.0  trump, british, britain, trade, russian, presi...   \n",
       "12886             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12887             6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "12888             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12889             5.0  british, company, uk, group, business, britain...   \n",
       "12890             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12891             3.0  trump, british, britain, trade, russian, presi...   \n",
       "12892             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12893             6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "12894             4.0  european, percent, market, stock, share, europ...   \n",
       "12895             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12896             6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "12897             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12898             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12899             3.0  trump, british, britain, trade, russian, presi...   \n",
       "12900             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12901             2.0  brexit, percent, year, economy, rate, month, b...   \n",
       "12902             2.0  brexit, percent, year, economy, rate, month, b...   \n",
       "12903             2.0  brexit, percent, year, economy, rate, month, b...   \n",
       "12904             5.0  british, company, uk, group, business, britain...   \n",
       "12905             5.0  british, company, uk, group, business, britain...   \n",
       "12906             5.0  british, company, uk, group, business, britain...   \n",
       "12907             7.0  usd, gbp, high, low, risk, week, fed, eur, dol...   \n",
       "12908             6.0  eu, deal, union, brexit, agreement, british, b...   \n",
       "\n",
       "       Num_Documents  Perc_Documents  \n",
       "0             1296.0          0.1004  \n",
       "1             2517.0          0.1950  \n",
       "2             1244.0          0.0964  \n",
       "3              958.0          0.0742  \n",
       "4              571.0          0.0442  \n",
       "5             1573.0          0.1219  \n",
       "6             2460.0          0.1906  \n",
       "7             2290.0          0.1774  \n",
       "8                NaN             NaN  \n",
       "9                NaN             NaN  \n",
       "10               NaN             NaN  \n",
       "11               NaN             NaN  \n",
       "12               NaN             NaN  \n",
       "13               NaN             NaN  \n",
       "14               NaN             NaN  \n",
       "15               NaN             NaN  \n",
       "16               NaN             NaN  \n",
       "17               NaN             NaN  \n",
       "18               NaN             NaN  \n",
       "19               NaN             NaN  \n",
       "20               NaN             NaN  \n",
       "21               NaN             NaN  \n",
       "22               NaN             NaN  \n",
       "23               NaN             NaN  \n",
       "24               NaN             NaN  \n",
       "25               NaN             NaN  \n",
       "26               NaN             NaN  \n",
       "27               NaN             NaN  \n",
       "28               NaN             NaN  \n",
       "29               NaN             NaN  \n",
       "...              ...             ...  \n",
       "12879            NaN             NaN  \n",
       "12880            NaN             NaN  \n",
       "12881            NaN             NaN  \n",
       "12882            NaN             NaN  \n",
       "12883            NaN             NaN  \n",
       "12884            NaN             NaN  \n",
       "12885            NaN             NaN  \n",
       "12886            NaN             NaN  \n",
       "12887            NaN             NaN  \n",
       "12888            NaN             NaN  \n",
       "12889            NaN             NaN  \n",
       "12890            NaN             NaN  \n",
       "12891            NaN             NaN  \n",
       "12892            NaN             NaN  \n",
       "12893            NaN             NaN  \n",
       "12894            NaN             NaN  \n",
       "12895            NaN             NaN  \n",
       "12896            NaN             NaN  \n",
       "12897            NaN             NaN  \n",
       "12898            NaN             NaN  \n",
       "12899            NaN             NaN  \n",
       "12900            NaN             NaN  \n",
       "12901            NaN             NaN  \n",
       "12902            NaN             NaN  \n",
       "12903            NaN             NaN  \n",
       "12904            NaN             NaN  \n",
       "12905            NaN             NaN  \n",
       "12906            NaN             NaN  \n",
       "12907            NaN             NaN  \n",
       "12908            NaN             NaN  \n",
       "\n",
       "[12909 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
